Unable to use a TTY - input is not a terminal or the right kind of file
E0912 04:10:49.398871  118347 v2.go:105] read /dev/stdin: bad file descriptor
Running the spark command k8s://https://10.204.0.1:443
Unable to use a TTY - input is not a terminal or the right kind of file
Unable to use a TTY - input is not a terminal or the right kind of file
E0912 04:10:54.678451  118374 v2.go:105] read /dev/stdin: bad file descriptor
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
20/09/12 11:10:57 INFO submit.LoggingPodStatusWatcherImpl: State changed, new state: 
	 pod name: spark-pipeline
	 namespace: sparktst5
	 labels: spark-app-selector -> spark-204f6caeee3a45e08d1515018ada3700, spark-role -> driver
	 pod uid: f81d17a0-0eb2-406a-8b7f-48dcc8c6d1d5
	 creation time: 2020-09-12T11:10:56Z
	 service account name: spark-exes
	 volumes: spark-local-dir-1, spark-conf-volume, spark-exes-token-zfpbj
	 node name: N/A
	 start time: N/A
	 container images: N/A
	 phase: Pending
	 status: []
20/09/12 11:10:57 INFO submit.LoggingPodStatusWatcherImpl: State changed, new state: 
	 pod name: spark-pipeline
	 namespace: sparktst5
	 labels: spark-app-selector -> spark-204f6caeee3a45e08d1515018ada3700, spark-role -> driver
	 pod uid: f81d17a0-0eb2-406a-8b7f-48dcc8c6d1d5
	 creation time: 2020-09-12T11:10:56Z
	 service account name: spark-exes
	 volumes: spark-local-dir-1, spark-conf-volume, spark-exes-token-zfpbj
	 node name: gke-shuvamoy-default-pool-0c327766-zdq0
	 start time: N/A
	 container images: N/A
	 phase: Pending
	 status: []
20/09/12 11:10:57 INFO submit.LoggingPodStatusWatcherImpl: State changed, new state: 
	 pod name: spark-pipeline
	 namespace: sparktst5
	 labels: spark-app-selector -> spark-204f6caeee3a45e08d1515018ada3700, spark-role -> driver
	 pod uid: f81d17a0-0eb2-406a-8b7f-48dcc8c6d1d5
	 creation time: 2020-09-12T11:10:56Z
	 service account name: spark-exes
	 volumes: spark-local-dir-1, spark-conf-volume, spark-exes-token-zfpbj
	 node name: gke-shuvamoy-default-pool-0c327766-zdq0
	 start time: 2020-09-12T11:10:57Z
	 container images: shuvamoy008/spark8s
	 phase: Pending
	 status: [ContainerStatus(containerID=null, image=shuvamoy008/spark8s, imageID=, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=false, restartCount=0, state=ContainerState(running=null, terminated=null, waiting=ContainerStateWaiting(message=null, reason=ContainerCreating, additionalProperties={}), additionalProperties={}), additionalProperties={})]
20/09/12 11:10:57 INFO submit.Client: Waiting for application sparkkafka-test123 to finish...
E0912 04:10:57.863155  118398 v2.go:105] read /dev/stdin: bad file descriptor
Running the spark command k8s://https://10.204.0.1:443
Unable to use a TTY - input is not a terminal or the right kind of file
E0912 04:11:03.112486  118411 v2.go:105] read /dev/stdin: bad file descriptor
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.3/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Exception in thread "main" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: https://10.204.0.1/api/v1/namespaces/sparktst5/pods. Message: Pod "postgresTospark" is invalid: metadata.name: Invalid value: "postgresTospark": a DNS-1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'). Received status: Status(apiVersion=v1, code=422, details=StatusDetails(causes=[StatusCause(field=metadata.name, message=Invalid value: "postgresTospark": a DNS-1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), reason=FieldValueInvalid, additionalProperties={})], group=null, kind=Pod, name=postgresTospark, retryAfterSeconds=null, uid=null, additionalProperties={}), kind=Status, message=Pod "postgresTospark" is invalid: metadata.name: Invalid value: "postgresTospark": a DNS-1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*'), metadata=ListMeta(_continue=null, remainingItemCount=null, resourceVersion=null, selfLink=null, additionalProperties={}), reason=Invalid, status=Failure, additionalProperties={}).
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.requestFailure(OperationSupport.java:510)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.assertResponseCode(OperationSupport.java:449)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:413)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleResponse(OperationSupport.java:372)
	at io.fabric8.kubernetes.client.dsl.base.OperationSupport.handleCreate(OperationSupport.java:241)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.handleCreate(BaseOperation.java:819)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:334)
	at io.fabric8.kubernetes.client.dsl.base.BaseOperation.create(BaseOperation.java:330)
	at org.apache.spark.deploy.k8s.submit.Client$$anonfun$run$2.apply(KubernetesClientApplication.scala:141)
	at org.apache.spark.deploy.k8s.submit.Client$$anonfun$run$2.apply(KubernetesClientApplication.scala:140)
	at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)
	at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:140)
	at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication$$anonfun$run$5.apply(KubernetesClientApplication.scala:250)
	at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication$$anonfun$run$5.apply(KubernetesClientApplication.scala:241)
	at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2543)
	at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:241)
	at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:204)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
20/09/12 11:11:05 INFO util.ShutdownHookManager: Shutdown hook called
20/09/12 11:11:05 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-304c6bc7-afab-4bf2-874c-2a3356a4f336
command terminated with exit code 1
20/09/12 11:11:24 INFO submit.LoggingPodStatusWatcherImpl: State changed, new state: 
	 pod name: spark-pipeline
	 namespace: sparktst5
	 labels: spark-app-selector -> spark-204f6caeee3a45e08d1515018ada3700, spark-role -> driver
	 pod uid: f81d17a0-0eb2-406a-8b7f-48dcc8c6d1d5
	 creation time: 2020-09-12T11:10:56Z
	 service account name: spark-exes
	 volumes: spark-local-dir-1, spark-conf-volume, spark-exes-token-zfpbj
	 node name: gke-shuvamoy-default-pool-0c327766-zdq0
	 start time: 2020-09-12T11:10:57Z
	 container images: shuvamoy008/spark8s:latest
	 phase: Running
	 status: [ContainerStatus(containerID=docker://0336744fe0d95226cd47fc574e980d93a0dc3bae808fe9365f345e4007a19565, image=shuvamoy008/spark8s:latest, imageID=docker-pullable://shuvamoy008/spark8s@sha256:915f4a4829e29c855fb675703caccd2817e2ecc52f58fe9dac7bda5b6088532d, lastState=ContainerState(running=null, terminated=null, waiting=null, additionalProperties={}), name=spark-kubernetes-driver, ready=true, restartCount=0, state=ContainerState(running=ContainerStateRunning(startedAt=2020-09-12T11:11:24Z, additionalProperties={}), terminated=null, waiting=null, additionalProperties={}), additionalProperties={})]
